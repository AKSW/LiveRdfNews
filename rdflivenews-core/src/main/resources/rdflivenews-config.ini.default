[search]
; the method how we look for patterns: NER or POS possible
method = NER
; the number of threads which should search for patterns
number-of-threads = 3

[general]
; this directory should not be inside the code repo
data-directory = /Users/gerb/Development/workspaces/experimental/rdflivenews
; website sentence crawl index
index = index
; we need this test directory only for the junit tests
test = test
; this is an index where the dbpedia types and labels are index TODO create documentation on how to generate it 
dbpedia = /Users/gerb/Development/workspaces/experimental/solr/dbpedia_resources/data/index

[deduplication]
threshold = 1
window = 1

[clustering]
similarityThreshold = 0.5

[refinement]
; only patterns which were learned from at least refinementOccurrenceThreshold pairs will be refined 
refinementOccurrenceThreshold = 3
; use the super class or the sub class as types for a pattern; SUPER_CLASS or SUB_CLASS
typing = SUPER_CLASS

[classes]
deduplication   = org.aksw.simba.rdflivenews.deduplication.impl.DummyDeduplication
tagging         = org.aksw.simba.rdflivenews.nlp.impl.NamedEntityAndOrPartOfSpeechNaturalLanguageTagger
refiner         = org.aksw.simba.rdflivenews.pattern.refinement.impl.DefaultPatternRefiner
scorer          = org.aksw.simba.rdflivenews.pattern.scoring.impl.WekaPatternScorer
cluster         = org.aksw.simba.rdflivenews.pattern.clustering.impl.DefaultPatternClustering
extraction      = org.aksw.simba.rdflivenews.rdf.impl.DefaultRdfExtraction
similarity      = org.aksw.simba.rdflivenews.pattern.similarity.impl.WordnetSimilarityMetric
mapping         = org.aksw.simba.rdflivenews.pattern.mapping.impl.DefaultDbpediaMapper
uriretrieval    = org.aksw.simba.rdflivenews.rdf.uri.impl.DefaultUriRetrieval 